{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1def1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "\n",
    "%matplotlib qt\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# import module with layers\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/model_module\")\n",
    "\n",
    "from adaptive_layer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3ae740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(5)\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f26c27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_train(name, y_label, static_f, adaptive_f, adaptive_nn, adaptive_conv_nn):\n",
    "    epochs = range(1, len(static_f)+1)\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot()\n",
    "    plt.title(name, fontsize=\"xx-large\")\n",
    "\n",
    "    ax.set_ylabel(y_label, fontsize=\"large\")\n",
    "    ax.set_xlabel('Epochs', fontsize=\"large\")\n",
    "\n",
    "    ax.plot(epochs, static_f, label='ReLU Function')\n",
    "    ax.plot(epochs, adaptive_f, label='Swish Function')\n",
    "    ax.plot(epochs, adaptive_nn, label='Adaptive NN')\n",
    "    ax.plot(epochs, adaptive_conv_nn, label='Adaptive Conv NN')\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab8cca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_test(name, static_f, adaptive_f, adaptive_nn, adaptive_conv_nn):\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot()\n",
    "    \n",
    "    x = [\"ReLU Function\", \"Swish Function\", \"Adaptive NN\", \"Adaptive Conv NN\"]\n",
    "    y = [static_f, adaptive_f, adaptive_nn, adaptive_conv_nn]\n",
    "    \n",
    "    plt.title(name, fontsize=\"xx-large\")\n",
    "    ax.set_ylabel(\"Accuracy\", fontsize=\"large\")\n",
    "    \n",
    "    ax.bar(x, y)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7b83af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('cifar10_pretrained_measurements.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81260211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(name, static_f_train, adaptive_f_train, adaptive_nn_train, adaptive_conv_nn_train, \n",
    "              static_f_test, adaptive_f_test, adaptive_nn_test, adaptive_conv_nn_test):\n",
    "    \n",
    "    epochs = len(static_f_train[0][:])\n",
    "    worksheet = workbook.add_worksheet(name)\n",
    "    \n",
    "    worksheet.write(1, 1, name + \" Training Loss\")\n",
    "    worksheet.write(1, 7, name + \" Training Accuracy\")\n",
    "    worksheet.write(1, 13, name + \" Test Accuracy\")\n",
    "    \n",
    "    worksheet.write(2, 1, \"Epochs\")\n",
    "    worksheet.write(2, 2, \"ReLU Function\")\n",
    "    worksheet.write(2, 3, \"Swish Function\")\n",
    "    worksheet.write(2, 4, \"Adaptive NN\")\n",
    "    worksheet.write(2, 5, \"Adaptive Conv NN\")\n",
    "    \n",
    "    worksheet.write(2, 7, \"Epochs\")\n",
    "    worksheet.write(2, 8, \"ReLU Function\")\n",
    "    worksheet.write(2, 9, \"Swish Function\")\n",
    "    worksheet.write(2, 10, \"Adaptive NN\")\n",
    "    worksheet.write(2, 11, \"Adaptive Conv NN\")\n",
    "    \n",
    "    worksheet.write(2, 13, \"Static Function\")\n",
    "    worksheet.write(2, 14, \"ReLU Function\")\n",
    "    worksheet.write(2, 15, \"Swish NN\")\n",
    "    worksheet.write(2, 16, \"Adaptive Conv NN\")\n",
    "    \n",
    "    worksheet.write(3, 13, static_f_test)\n",
    "    worksheet.write(3, 14, adaptive_f_test)\n",
    "    worksheet.write(3, 15, adaptive_nn_test)\n",
    "    worksheet.write(3, 16, adaptive_conv_nn_test)\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        worksheet.write(3+i, 1, i+1)\n",
    "        worksheet.write(3+i, 2, static_f_train[0][i])\n",
    "        worksheet.write(3+i, 3, adaptive_f_train[0][i])\n",
    "        worksheet.write(3+i, 4, adaptive_nn_train[0][i])\n",
    "        worksheet.write(3+i, 5, adaptive_conv_nn_train[0][i])\n",
    "        \n",
    "        worksheet.write(3+i, 7, i+1)\n",
    "        worksheet.write(3+i, 8, static_f_train[1][i])\n",
    "        worksheet.write(3+i, 9, adaptive_f_train[1][i])\n",
    "        worksheet.write(3+i, 10, adaptive_nn_train[1][i])\n",
    "        worksheet.write(3+i, 11, adaptive_conv_nn_train[1][i])\n",
    "    \n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4965b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acfbf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 5\n",
    "name = \"Cifar10 Pretrained Conv\"\n",
    "pretrained_model = keras.models.load_model(\"pretrained_m\")\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "initial_learning_rate = 0.001\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True)\n",
    "\n",
    "flag = measurements = 1\n",
    "\n",
    "static_f_hist = np.zeros(shape=[2, EPOCHS])\n",
    "adaptive_f_hist = np.zeros(shape=[2, EPOCHS])\n",
    "adaptive_nn_hist = np.zeros(shape=[2, EPOCHS])\n",
    "adaptive_conv_nn_hist = np.zeros(shape=[2, EPOCHS])\n",
    "\n",
    "static_f_test = 0\n",
    "adaptive_f_test = 0\n",
    "adaptive_nn_test = 0\n",
    "adaptive_conv_nn_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e99d616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 16, 16, 64)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 8, 8, 128)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 256)         295168    \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 256)         590080    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 4, 4, 256)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1145408 (4.37 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 1145408 (4.37 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8df7f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_f_model = keras.Sequential([\n",
    "    pretrained_model,\n",
    "    keras.layers.Dense(1000, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55a602e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_f_model = keras.Sequential([\n",
    "    pretrained_model,\n",
    "    keras.layers.Dense(1000, activation=tf.nn.swish),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99177453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Layer\n",
    "adaptive_nn_model = keras.Sequential([\n",
    "    pretrained_model,\n",
    "    AdaptiveLayer(1000, structure=[3, 2, 1], inner_hidden_activation=tf.nn.relu, \n",
    "                  inner_out_activation=tf.nn.leaky_relu, skip_w=0.3), \n",
    "    AdaptiveLayer(10, structure=[5, 2, 1], inner_hidden_activation=tf.nn.relu, \n",
    "                  inner_out_activation=tf.nn.softmax, skip_w=0.2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ddfa62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Layer based on 1D Conv\n",
    "adaptive_conv_nn_model = AdaptiveModel([\n",
    "    pretrained_model,\n",
    "    AdaptiveLayerConv(1000, structure=[24, 12], split=1, noise=0, skip_w=0.9, \n",
    "                      inner_hidden_activation=tf.nn.leaky_relu, inner_out_activation=tf.nn.leaky_relu), \n",
    "    AdaptiveLayerConv(10, structure=[32, 16, 8], split=2, noise=0, skip_w=0.9, \n",
    "                      inner_hidden_activation=tf.nn.leaky_relu, inner_out_activation=tf.nn.softmax) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38652992",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_f_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=lr_schedule), \n",
    "                       loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "244180f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_f_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=lr_schedule), \n",
    "                       loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca5dd089",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_nn_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=lr_schedule), \n",
    "                       loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dc0a4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_conv_nn_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=lr_schedule), \n",
    "                       loss=\"categorical_crossentropy\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee6ac750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 57s 73ms/step - loss: 0.3696 - accuracy: 0.8712\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 64s 81ms/step - loss: 0.1384 - accuracy: 0.9510\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.0651 - accuracy: 0.9778\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.0387 - accuracy: 0.9880\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 71s 90ms/step - loss: 0.0247 - accuracy: 0.9925\n"
     ]
    }
   ],
   "source": [
    "hist = static_f_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fece44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_f_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "static_f_hist[1][:] += np.array(hist.history[\"accuracy\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c508df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.3675 - accuracy: 0.8712\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 70s 90ms/step - loss: 0.1338 - accuracy: 0.9537\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.0588 - accuracy: 0.9800\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.0322 - accuracy: 0.9898\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.0225 - accuracy: 0.9927\n"
     ]
    }
   ],
   "source": [
    "hist = adaptive_f_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a562778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_f_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "adaptive_f_hist[1][:] += np.array(hist.history[\"accuracy\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61fe894f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 59s 75ms/step - loss: 0.5964 - accuracy: 0.7889\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 0.2075 - accuracy: 0.9342\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.1070 - accuracy: 0.9635\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 70s 90ms/step - loss: 0.0541 - accuracy: 0.9828\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.0288 - accuracy: 0.9913\n"
     ]
    }
   ],
   "source": [
    "hist = adaptive_nn_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8f541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_nn_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "adaptive_nn_hist[1][:] += np.array(hist.history[\"accuracy\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cfa80f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 63s 80ms/step - loss: 0.3816 - accuracy: 0.8675\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 69s 88ms/step - loss: 0.1518 - accuracy: 0.9463\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 72s 92ms/step - loss: 0.0916 - accuracy: 0.9680\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 73s 93ms/step - loss: 0.0568 - accuracy: 0.9808\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 74s 95ms/step - loss: 0.0375 - accuracy: 0.9879\n"
     ]
    }
   ],
   "source": [
    "hist = adaptive_conv_nn_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cc4d7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_conv_nn_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "adaptive_conv_nn_hist[1][:] += np.array(hist.history[\"accuracy\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df20e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 42ms/step - loss: 1.4376 - accuracy: 0.7908\n"
     ]
    }
   ],
   "source": [
    "static_f_test += static_f_model.evaluate(x_test, y_test)[1]/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cc36cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 40ms/step - loss: 1.4759 - accuracy: 0.7874\n"
     ]
    }
   ],
   "source": [
    "adaptive_f_test += adaptive_f_model.evaluate(x_test, y_test)[1]/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19df7397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 41ms/step - loss: 1.3946 - accuracy: 0.7845\n"
     ]
    }
   ],
   "source": [
    "adaptive_nn_test += adaptive_nn_model.evaluate(x_test, y_test)[1]/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce1aae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 41ms/step - loss: 1.5245 - accuracy: 0.7804\n",
      "---------FINISH---------\n"
     ]
    }
   ],
   "source": [
    "adaptive_conv_nn_test += adaptive_conv_nn_model.evaluate(x_test, y_test)[1]/measurements\n",
    "flag -= 1\n",
    "if(flag == 0):\n",
    "    print(\"---------FINISH---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e08645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc1dda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Function model\n",
      "Test accuracy :  0.7907999753952026\n",
      "\n",
      "Adaptive Function model\n",
      "Test accuracy :  0.7874000072479248\n",
      "\n",
      "Adaptive NN model\n",
      "Test accuracy :  0.784500002861023\n",
      "\n",
      "Adaptive Conv NN model\n",
      "Test accuracy :  0.7803999781608582\n"
     ]
    }
   ],
   "source": [
    "print(\"Static Function model\\nTest accuracy : \", static_f_test)\n",
    "print(\"\\nAdaptive Function model\\nTest accuracy : \", adaptive_f_test)\n",
    "print(\"\\nAdaptive NN model\\nTest accuracy : \", adaptive_nn_test)\n",
    "print(\"\\nAdaptive Conv NN model\\nTest accuracy : \", adaptive_conv_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "49fe6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "illustrate_train(name+\" Training Loss\", \"Loss\", static_f_hist[0][:], \n",
    "                 adaptive_f_hist[0][:], adaptive_nn_hist[0][:], adaptive_conv_nn_hist[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ed4731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "illustrate_train(name + \" Training Accuracy\", \"Accuracy\", static_f_hist[1][:], \n",
    "                 adaptive_f_hist[1][:], adaptive_nn_hist[1][:], adaptive_conv_nn_hist[1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8385dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "illustrate_test(name + \" Test Accuracy\", \n",
    "                static_f_test, adaptive_f_test, adaptive_nn_test, adaptive_conv_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "309eb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(name, static_f_hist, adaptive_f_hist, adaptive_nn_hist, \n",
    "          adaptive_conv_nn_hist, static_f_test, adaptive_f_test, adaptive_nn_test, adaptive_conv_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07533a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

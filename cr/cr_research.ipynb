{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1def1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import xlsxwriter\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "# import module with layers\n",
    "import sys\n",
    "import os\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"/model_module\")\n",
    "\n",
    "from adaptive_layer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef3ae740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(5)\n",
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f26c27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_train(name, y_label, static_f, adaptive_f, adaptive_nn, adaptive_conv_nn):\n",
    "    epochs = range(1, len(static_f)+1)\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot()\n",
    "    plt.title(name, fontsize=\"xx-large\")\n",
    "\n",
    "    ax.set_ylabel(y_label, fontsize=\"large\")\n",
    "    ax.set_xlabel('Epochs', fontsize=\"large\")\n",
    "\n",
    "    ax.plot(epochs, static_f, label='ReLU Function')\n",
    "    ax.plot(epochs, adaptive_f, label='Swish Function')\n",
    "    ax.plot(epochs, adaptive_nn, label='Adaptive NN')\n",
    "    ax.plot(epochs, adaptive_conv_nn, label='Adaptive Conv NN')\n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8cca84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def illustrate_test(name, static_f, adaptive_f, adaptive_nn, adaptive_conv_nn):\n",
    "    fig = plt.figure(figsize=(10,7))\n",
    "    ax = fig.add_subplot()\n",
    "    \n",
    "    x = [\"ReLU Function\", \"Swish Function\", \"Adaptive NN\", \"Adaptive Conv NN\"]\n",
    "    y = [static_f, adaptive_f, adaptive_nn, adaptive_conv_nn]\n",
    "    \n",
    "    plt.title(name, fontsize=\"xx-large\")\n",
    "    ax.set_ylabel(\"mean absolute error\", fontsize=\"large\")\n",
    "    \n",
    "    ax.bar(x, y)\n",
    "    \n",
    "    plt.grid()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7b83af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = xlsxwriter.Workbook('cr_measurements.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81260211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(name, static_f_train, adaptive_f_train, adaptive_nn_train, adaptive_conv_nn_train, \n",
    "              static_f_test, adaptive_f_test, adaptive_nn_test, adaptive_conv_nn_test):\n",
    "    \n",
    "    epochs = len(static_f_train[0][:])\n",
    "    worksheet = workbook.add_worksheet(name)\n",
    "    \n",
    "    worksheet.write(1, 1, name + \" Training Loss\")\n",
    "    worksheet.write(1, 7, name + \" Training Accuracy\")\n",
    "    worksheet.write(1, 13, name + \" Test Accuracy\")\n",
    "    \n",
    "    worksheet.write(2, 1, \"Epochs\")\n",
    "    worksheet.write(2, 2, \"ReLU Function\")\n",
    "    worksheet.write(2, 3, \"Swish Function\")\n",
    "    worksheet.write(2, 4, \"Adaptive NN\")\n",
    "    worksheet.write(2, 5, \"Adaptive Conv NN\")\n",
    "    \n",
    "    worksheet.write(2, 7, \"Epochs\")\n",
    "    worksheet.write(2, 8, \"ReLU Function\")\n",
    "    worksheet.write(2, 9, \"Swish Function\")\n",
    "    worksheet.write(2, 10, \"Adaptive NN\")\n",
    "    worksheet.write(2, 11, \"Adaptive Conv NN\")\n",
    "    \n",
    "    worksheet.write(2, 13, \"ReLU Function\")\n",
    "    worksheet.write(2, 14, \"Swish Function\")\n",
    "    worksheet.write(2, 15, \"Adaptive NN\")\n",
    "    worksheet.write(2, 16, \"Adaptive Conv NN\")\n",
    "    \n",
    "    worksheet.write(3, 13, static_f_test)\n",
    "    worksheet.write(3, 14, adaptive_f_test)\n",
    "    worksheet.write(3, 15, adaptive_nn_test)\n",
    "    worksheet.write(3, 16, adaptive_conv_nn_test)\n",
    "    \n",
    "    for i in range(0, epochs):\n",
    "        worksheet.write(3+i, 1, i+1)\n",
    "        worksheet.write(3+i, 2, static_f_train[0][i])\n",
    "        worksheet.write(3+i, 3, adaptive_f_train[0][i])\n",
    "        worksheet.write(3+i, 4, adaptive_nn_train[0][i])\n",
    "        worksheet.write(3+i, 5, adaptive_conv_nn_train[0][i])\n",
    "        \n",
    "        worksheet.write(3+i, 7, i+1)\n",
    "        worksheet.write(3+i, 8, static_f_train[1][i])\n",
    "        worksheet.write(3+i, 9, adaptive_f_train[1][i])\n",
    "        worksheet.write(3+i, 10, adaptive_nn_train[1][i])\n",
    "        worksheet.write(3+i, 11, adaptive_conv_nn_train[1][i])\n",
    "    \n",
    "    workbook.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4965b33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "x1 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x2 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x3 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x4 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x5 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x6 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x7 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x8 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x9 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "x10 = tf.random.uniform(shape=(2500, 1), minval=-1, maxval=1)\n",
    "\n",
    "x = np.array([x1, x2, x3, x4, x5, x6, x7, x8, x9, x10])\n",
    "x = np.reshape(x.transpose(), (x1.shape[0], 10))\n",
    "\n",
    "x = tf.Variable(x)\n",
    "y = np.array([(0.2*x[i][0]*x[i][1]*x[i][1]+x[i][2]+0.05*x[i][3]+2*x[i][4]+0.5*x[i][5]+0.1*x[i][7]\n",
    "              -12*x[i][7]+x[i][8]*x[i][9]) for i in range(x.shape[0])], dtype=float)\n",
    "\n",
    "x_train, x_test = x[:2000], x[2000:]\n",
    "y_train, y_test = y[:2000], y[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acfbf2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "name = \"Classical regression\"\n",
    "\n",
    "# measurement repetitions\n",
    "flag = measurements = 5\n",
    "\n",
    "static_f_hist = np.zeros(shape=[2, EPOCHS])\n",
    "adaptive_f_hist = np.zeros(shape=[2, EPOCHS])\n",
    "adaptive_nn_hist = np.zeros(shape=[2, EPOCHS])\n",
    "adaptive_conv_nn_hist = np.zeros(shape=[2, EPOCHS])\n",
    "\n",
    "static_f_test = 0\n",
    "adaptive_f_test = 0\n",
    "adaptive_nn_test = 0\n",
    "adaptive_conv_nn_test = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e99d616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8df7f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_f_model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "55a602e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_f_model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=tf.nn.swish),\n",
    "    keras.layers.Dense(1, activation=\"linear\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "99177453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Layer\n",
    "adaptive_nn_model = AdaptiveModel([\n",
    "    AdaptiveLayer(100, structure=[4, 2, 1], inner_hidden_activation=tf.nn.leaky_relu, \n",
    "                  inner_out_activation=tf.nn.relu, skip_w=1.7), \n",
    "    AdaptiveLayer(1, structure=[8, 4, 1], inner_hidden_activation=tf.nn.relu, skip_w=0.9) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ddfa62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adaptive Layer based on 1D Conv\n",
    "adaptive_conv_nn_model = AdaptiveModel([\n",
    "    AdaptiveLayerConv(100, structure=[16], split=2, noise=0, skip_w=3.5, \n",
    "                      inner_hidden_activation=tf.nn.leaky_relu, inner_out_activation=tf.nn.leaky_relu), \n",
    "    AdaptiveLayerConv(1, structure=[32], split=2, noise=0, skip_w=1.5, \n",
    "                      inner_hidden_activation=tf.nn.leaky_relu) \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "38652992",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_f_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=0.001), \n",
    "                       loss=\"mse\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "244180f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_f_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=0.001), \n",
    "                       loss=\"mse\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ca5dd089",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_nn_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=0.001), \n",
    "                       loss=\"mse\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "dc0a4b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_conv_nn_model.compile(optimizer=tf.optimizers.legacy.Adam(learning_rate=0.001), \n",
    "                       loss=\"mse\", metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ee6ac750",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 502us/step - loss: 48.0974 - mean_absolute_error: 5.9848\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 537us/step - loss: 44.4285 - mean_absolute_error: 5.7588\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 497us/step - loss: 39.9770 - mean_absolute_error: 5.4650\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 466us/step - loss: 34.1041 - mean_absolute_error: 5.0501\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 473us/step - loss: 26.9489 - mean_absolute_error: 4.4819\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 473us/step - loss: 19.2754 - mean_absolute_error: 3.7724\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 462us/step - loss: 12.0443 - mean_absolute_error: 2.9520\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 467us/step - loss: 6.3918 - mean_absolute_error: 2.1037\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 473us/step - loss: 2.8320 - mean_absolute_error: 1.3472\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 443us/step - loss: 1.0922 - mean_absolute_error: 0.7850\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 429us/step - loss: 0.4757 - mean_absolute_error: 0.4983\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 437us/step - loss: 0.2977 - mean_absolute_error: 0.4080\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 425us/step - loss: 0.2517 - mean_absolute_error: 0.3909\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 414us/step - loss: 0.2361 - mean_absolute_error: 0.3847\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 412us/step - loss: 0.2261 - mean_absolute_error: 0.3783\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 444us/step - loss: 0.2160 - mean_absolute_error: 0.3707\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 436us/step - loss: 0.2073 - mean_absolute_error: 0.3632\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 428us/step - loss: 0.1975 - mean_absolute_error: 0.3548\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 426us/step - loss: 0.1893 - mean_absolute_error: 0.3473\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 438us/step - loss: 0.1807 - mean_absolute_error: 0.3392\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 427us/step - loss: 0.1726 - mean_absolute_error: 0.3318\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 433us/step - loss: 0.1645 - mean_absolute_error: 0.3233\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 440us/step - loss: 0.1567 - mean_absolute_error: 0.3156\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 432us/step - loss: 0.1487 - mean_absolute_error: 0.3071\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 415us/step - loss: 0.1417 - mean_absolute_error: 0.3006\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 428us/step - loss: 0.1340 - mean_absolute_error: 0.2916\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 433us/step - loss: 0.1271 - mean_absolute_error: 0.2843\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 453us/step - loss: 0.1201 - mean_absolute_error: 0.2763\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 443us/step - loss: 0.1135 - mean_absolute_error: 0.2683\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 432us/step - loss: 0.1069 - mean_absolute_error: 0.2593\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 428us/step - loss: 0.1005 - mean_absolute_error: 0.2521\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 444us/step - loss: 0.0947 - mean_absolute_error: 0.2439\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 450us/step - loss: 0.0888 - mean_absolute_error: 0.2365\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 445us/step - loss: 0.0835 - mean_absolute_error: 0.2285\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 443us/step - loss: 0.0784 - mean_absolute_error: 0.2219\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 442us/step - loss: 0.0735 - mean_absolute_error: 0.2156\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 450us/step - loss: 0.0690 - mean_absolute_error: 0.2081\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 460us/step - loss: 0.0651 - mean_absolute_error: 0.2011\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 447us/step - loss: 0.0613 - mean_absolute_error: 0.1953\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 445us/step - loss: 0.0582 - mean_absolute_error: 0.1896\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 446us/step - loss: 0.0546 - mean_absolute_error: 0.1838\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 428us/step - loss: 0.0519 - mean_absolute_error: 0.1781\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 519us/step - loss: 0.0491 - mean_absolute_error: 0.1745\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 496us/step - loss: 0.0470 - mean_absolute_error: 0.1694\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 508us/step - loss: 0.0447 - mean_absolute_error: 0.1651\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 495us/step - loss: 0.0424 - mean_absolute_error: 0.1612\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 503us/step - loss: 0.0408 - mean_absolute_error: 0.1576\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 506us/step - loss: 0.0389 - mean_absolute_error: 0.1537\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 501us/step - loss: 0.0374 - mean_absolute_error: 0.1500\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 519us/step - loss: 0.0358 - mean_absolute_error: 0.1474\n"
     ]
    }
   ],
   "source": [
    "hist = static_f_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "fece44b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "static_f_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "static_f_hist[1][:] += np.array(hist.history[\"mean_absolute_error\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8c508df0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 517us/step - loss: 47.2806 - mean_absolute_error: 5.9310\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 513us/step - loss: 43.7915 - mean_absolute_error: 5.7154\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 488us/step - loss: 39.7718 - mean_absolute_error: 5.4508\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 474us/step - loss: 34.8855 - mean_absolute_error: 5.1124\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 480us/step - loss: 29.2506 - mean_absolute_error: 4.6860\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 487us/step - loss: 23.2237 - mean_absolute_error: 4.1758\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 477us/step - loss: 17.1670 - mean_absolute_error: 3.5872\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 488us/step - loss: 11.5838 - mean_absolute_error: 2.9359\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 505us/step - loss: 6.9401 - mean_absolute_error: 2.2660\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 488us/step - loss: 3.5787 - mean_absolute_error: 1.6188\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 460us/step - loss: 1.5990 - mean_absolute_error: 1.0718\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 446us/step - loss: 0.6348 - mean_absolute_error: 0.6585\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 469us/step - loss: 0.2600 - mean_absolute_error: 0.4069\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 455us/step - loss: 0.1427 - mean_absolute_error: 0.2947\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 451us/step - loss: 0.1118 - mean_absolute_error: 0.2577\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 446us/step - loss: 0.1021 - mean_absolute_error: 0.2468\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 432us/step - loss: 0.0980 - mean_absolute_error: 0.2422\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 427us/step - loss: 0.0942 - mean_absolute_error: 0.2369\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 438us/step - loss: 0.0910 - mean_absolute_error: 0.2328\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 452us/step - loss: 0.0881 - mean_absolute_error: 0.2293\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 444us/step - loss: 0.0849 - mean_absolute_error: 0.2246\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 443us/step - loss: 0.0820 - mean_absolute_error: 0.2207\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 447us/step - loss: 0.0790 - mean_absolute_error: 0.2168\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 446us/step - loss: 0.0762 - mean_absolute_error: 0.2121\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 451us/step - loss: 0.0732 - mean_absolute_error: 0.2081\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 448us/step - loss: 0.0702 - mean_absolute_error: 0.2040\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 463us/step - loss: 0.0675 - mean_absolute_error: 0.1996\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 502us/step - loss: 0.0644 - mean_absolute_error: 0.1949\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 510us/step - loss: 0.0616 - mean_absolute_error: 0.1906\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 510us/step - loss: 0.0590 - mean_absolute_error: 0.1863\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 519us/step - loss: 0.0560 - mean_absolute_error: 0.1816\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 517us/step - loss: 0.0533 - mean_absolute_error: 0.1774\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 512us/step - loss: 0.0504 - mean_absolute_error: 0.1723\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 511us/step - loss: 0.0478 - mean_absolute_error: 0.1681\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 529us/step - loss: 0.0447 - mean_absolute_error: 0.1629\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 431us/step - loss: 0.0418 - mean_absolute_error: 0.1573\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 570us/step - loss: 0.0391 - mean_absolute_error: 0.1521\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 550us/step - loss: 0.0365 - mean_absolute_error: 0.1468\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 591us/step - loss: 0.0339 - mean_absolute_error: 0.1423\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 492us/step - loss: 0.0315 - mean_absolute_error: 0.1368\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 465us/step - loss: 0.0290 - mean_absolute_error: 0.1314\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 459us/step - loss: 0.0266 - mean_absolute_error: 0.1256\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 458us/step - loss: 0.0244 - mean_absolute_error: 0.1206\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 471us/step - loss: 0.0222 - mean_absolute_error: 0.1150\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 469us/step - loss: 0.0202 - mean_absolute_error: 0.1095\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 464us/step - loss: 0.0182 - mean_absolute_error: 0.1039\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 471us/step - loss: 0.0163 - mean_absolute_error: 0.0988\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 465us/step - loss: 0.0146 - mean_absolute_error: 0.0935\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 452us/step - loss: 0.0131 - mean_absolute_error: 0.0883\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 454us/step - loss: 0.0117 - mean_absolute_error: 0.0837\n"
     ]
    }
   ],
   "source": [
    "hist = adaptive_f_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a562778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_f_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "adaptive_f_hist[1][:] += np.array(hist.history[\"mean_absolute_error\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61fe894f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 46.4084 - mean_absolute_error: 5.8477\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 31.2740 - mean_absolute_error: 4.5882\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 18.3537 - mean_absolute_error: 2.9448\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 11.0985 - mean_absolute_error: 2.4639\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 5.0929 - mean_absolute_error: 1.8070\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 1.7600 - mean_absolute_error: 1.0563\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6611 - mean_absolute_error: 0.6511\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3377 - mean_absolute_error: 0.4708\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2175 - mean_absolute_error: 0.3748\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1546 - mean_absolute_error: 0.3115\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1153 - mean_absolute_error: 0.2668\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0949 - mean_absolute_error: 0.2423\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0784 - mean_absolute_error: 0.2192\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0681 - mean_absolute_error: 0.2039\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0604 - mean_absolute_error: 0.1925\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0549 - mean_absolute_error: 0.1828\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0486 - mean_absolute_error: 0.1719\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0439 - mean_absolute_error: 0.1633\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0396 - mean_absolute_error: 0.1543\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0366 - mean_absolute_error: 0.1488\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0326 - mean_absolute_error: 0.1403\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0306 - mean_absolute_error: 0.1347\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0272 - mean_absolute_error: 0.1284\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0248 - mean_absolute_error: 0.1222\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0227 - mean_absolute_error: 0.1171\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0212 - mean_absolute_error: 0.1131\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0196 - mean_absolute_error: 0.1084\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0185 - mean_absolute_error: 0.1048\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0171 - mean_absolute_error: 0.1013\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0169 - mean_absolute_error: 0.1010\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0159 - mean_absolute_error: 0.0984\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0153 - mean_absolute_error: 0.0961\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0131 - mean_absolute_error: 0.0892\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0131 - mean_absolute_error: 0.0895\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0120 - mean_absolute_error: 0.0848\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0110 - mean_absolute_error: 0.0815\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0105 - mean_absolute_error: 0.0792\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0109 - mean_absolute_error: 0.0813\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0101 - mean_absolute_error: 0.0781\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_absolute_error: 0.0748\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0088 - mean_absolute_error: 0.0724\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0085 - mean_absolute_error: 0.0716\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_absolute_error: 0.0700\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_absolute_error: 0.0699\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0690\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0075 - mean_absolute_error: 0.0673\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_absolute_error: 0.0662\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_absolute_error: 0.0656\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0069 - mean_absolute_error: 0.0646\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0066 - mean_absolute_error: 0.0627\n"
     ]
    }
   ],
   "source": [
    "hist = adaptive_nn_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e8f541f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_nn_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "adaptive_nn_hist[1][:] += np.array(hist.history[\"mean_absolute_error\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3cfa80f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 44.4916 - mean_absolute_error: 5.7429\n",
      "Epoch 2/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 17.8558 - mean_absolute_error: 3.3663\n",
      "Epoch 3/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.9787 - mean_absolute_error: 0.8142\n",
      "Epoch 4/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.4447 - mean_absolute_error: 0.5578\n",
      "Epoch 5/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.3312 - mean_absolute_error: 0.4797\n",
      "Epoch 6/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.2505 - mean_absolute_error: 0.4165\n",
      "Epoch 7/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1951 - mean_absolute_error: 0.3634\n",
      "Epoch 8/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1534 - mean_absolute_error: 0.3184\n",
      "Epoch 9/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1252 - mean_absolute_error: 0.2819\n",
      "Epoch 10/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.1051 - mean_absolute_error: 0.2576\n",
      "Epoch 11/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0834 - mean_absolute_error: 0.2269\n",
      "Epoch 12/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0721 - mean_absolute_error: 0.2082\n",
      "Epoch 13/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0615 - mean_absolute_error: 0.1907\n",
      "Epoch 14/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0516 - mean_absolute_error: 0.1747\n",
      "Epoch 15/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0450 - mean_absolute_error: 0.1632\n",
      "Epoch 16/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0397 - mean_absolute_error: 0.1535\n",
      "Epoch 17/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0339 - mean_absolute_error: 0.1401\n",
      "Epoch 18/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0297 - mean_absolute_error: 0.1319\n",
      "Epoch 19/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0242 - mean_absolute_error: 0.1184\n",
      "Epoch 20/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0210 - mean_absolute_error: 0.1104\n",
      "Epoch 21/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0189 - mean_absolute_error: 0.1059\n",
      "Epoch 22/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0175 - mean_absolute_error: 0.1019\n",
      "Epoch 23/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0163 - mean_absolute_error: 0.0992\n",
      "Epoch 24/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0150 - mean_absolute_error: 0.0959\n",
      "Epoch 25/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0132 - mean_absolute_error: 0.0900\n",
      "Epoch 26/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0137 - mean_absolute_error: 0.0910\n",
      "Epoch 27/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0121 - mean_absolute_error: 0.0860\n",
      "Epoch 28/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0112 - mean_absolute_error: 0.0824\n",
      "Epoch 29/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0106 - mean_absolute_error: 0.0807\n",
      "Epoch 30/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0100 - mean_absolute_error: 0.0786\n",
      "Epoch 31/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0097 - mean_absolute_error: 0.0771\n",
      "Epoch 32/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0094 - mean_absolute_error: 0.0764\n",
      "Epoch 33/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0085 - mean_absolute_error: 0.0729\n",
      "Epoch 34/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0082 - mean_absolute_error: 0.0715\n",
      "Epoch 35/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0078 - mean_absolute_error: 0.0689\n",
      "Epoch 36/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0073 - mean_absolute_error: 0.0669\n",
      "Epoch 37/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0080 - mean_absolute_error: 0.0696\n",
      "Epoch 38/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0075 - mean_absolute_error: 0.0681\n",
      "Epoch 39/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0072 - mean_absolute_error: 0.0669\n",
      "Epoch 40/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0071 - mean_absolute_error: 0.0668\n",
      "Epoch 41/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0068 - mean_absolute_error: 0.0653\n",
      "Epoch 42/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0068 - mean_absolute_error: 0.0648\n",
      "Epoch 43/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0065 - mean_absolute_error: 0.0635\n",
      "Epoch 44/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0068 - mean_absolute_error: 0.0644\n",
      "Epoch 45/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0061 - mean_absolute_error: 0.0612\n",
      "Epoch 46/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0064 - mean_absolute_error: 0.0635\n",
      "Epoch 47/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0062 - mean_absolute_error: 0.0621\n",
      "Epoch 48/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0059 - mean_absolute_error: 0.0610\n",
      "Epoch 49/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0059 - mean_absolute_error: 0.0606\n",
      "Epoch 50/50\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.0055 - mean_absolute_error: 0.0589\n"
     ]
    }
   ],
   "source": [
    "hist = adaptive_conv_nn_model.fit(x_train, y_train, epochs=EPOCHS, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "cc4d7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_conv_nn_hist[0][:] += np.array(hist.history[\"loss\"])/measurements\n",
    "adaptive_conv_nn_hist[1][:] += np.array(hist.history[\"mean_absolute_error\"])/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "df20e870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 502us/step - loss: 0.0435 - mean_absolute_error: 0.1623\n"
     ]
    }
   ],
   "source": [
    "static_f_test += static_f_model.evaluate(x_test, y_test)[1]/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5cc36cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 523us/step - loss: 0.0134 - mean_absolute_error: 0.0880\n"
     ]
    }
   ],
   "source": [
    "adaptive_f_test += adaptive_f_model.evaluate(x_test, y_test)[1]/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "19df7397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 742us/step - loss: 0.0108 - mean_absolute_error: 0.0764\n"
     ]
    }
   ],
   "source": [
    "adaptive_nn_test += adaptive_nn_model.evaluate(x_test, y_test)[1]/measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ce1aae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 714us/step - loss: 0.0076 - mean_absolute_error: 0.0685\n",
      "---------FINISH---------\n"
     ]
    }
   ],
   "source": [
    "adaptive_conv_nn_test += adaptive_conv_nn_model.evaluate(x_test, y_test)[1]/measurements\n",
    "flag -= 1\n",
    "if(flag == 0):\n",
    "    print(\"---------FINISH---------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e08645",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bc1dda17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Static Function model\n",
      "Test mean_absolute_error :  0.16776592433452606\n",
      "\n",
      "Adaptive Function model\n",
      "Test mean_absolute_error :  0.09616599977016449\n",
      "\n",
      "Adaptive NN model\n",
      "Test mean_absolute_error :  0.07488027960062027\n",
      "\n",
      "Adaptive Conv NN model\n",
      "Test mean_absolute_error :  0.0675840362906456\n"
     ]
    }
   ],
   "source": [
    "print(\"Static Function model\\nTest mean_absolute_error : \", static_f_test)\n",
    "print(\"\\nAdaptive Function model\\nTest mean_absolute_error : \", adaptive_f_test)\n",
    "print(\"\\nAdaptive NN model\\nTest mean_absolute_error : \", adaptive_nn_test)\n",
    "print(\"\\nAdaptive Conv NN model\\nTest mean_absolute_error : \", adaptive_conv_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "49fe6589",
   "metadata": {},
   "outputs": [],
   "source": [
    "illustrate_train(name+\" Training Loss\", \"Loss\", static_f_hist[0][:], \n",
    "                 adaptive_f_hist[0][:], adaptive_nn_hist[0][:], adaptive_conv_nn_hist[0][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2ed4731a",
   "metadata": {},
   "outputs": [],
   "source": [
    "illustrate_train(name + \" Training Mean Absolute Error\", \"mean absolute error\", static_f_hist[1][:], \n",
    "                 adaptive_f_hist[1][:], adaptive_nn_hist[1][:], adaptive_conv_nn_hist[1][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8385dc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "illustrate_test(name + \" Test\", \n",
    "                static_f_test, adaptive_f_test, adaptive_nn_test, adaptive_conv_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "309eb3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_data(name, static_f_hist, adaptive_f_hist, adaptive_nn_hist, \n",
    "          adaptive_conv_nn_hist, static_f_test, adaptive_f_test, adaptive_nn_test, adaptive_conv_nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42ed4e-479a-4f04-bb4e-d20f814a9ae7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
